{"bucket": "creative", "run": 0, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 0, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 0, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 0, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 0, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 0, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 0, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 1, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 1, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 1, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 1, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 1, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 1, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 1, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 2, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 2, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 2, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 2, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 2, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 2, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 2, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 3, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 3, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 3, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 3, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 3, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 3, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 3, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 4, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 4, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 4, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 4, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 4, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 4, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 4, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 5, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 5, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 5, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 5, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 5, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 5, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 5, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 6, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 6, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 6, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 6, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 6, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 6, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 6, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 7, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 7, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 7, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 7, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 7, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 7, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 7, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 8, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 8, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 8, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 8, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 8, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 8, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 8, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 9, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 9, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 9, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 9, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 9, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 9, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 9, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 10, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 10, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 10, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 10, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 10, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 10, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 10, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 11, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 11, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 11, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 11, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 11, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 11, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 11, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 12, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 12, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 12, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 12, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 12, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 12, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 12, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 13, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 13, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 13, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 13, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 13, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 13, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 13, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 14, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 14, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 14, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 14, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 14, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 14, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 14, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 15, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 15, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 15, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 15, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 15, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 15, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 15, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 16, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 16, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 16, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 16, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 16, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 16, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 16, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 17, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 17, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 17, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 17, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 17, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 17, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 17, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 18, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 18, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 18, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 18, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 18, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 18, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 18, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 19, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 19, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 19, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 19, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 19, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 19, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 19, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 20, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 20, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 20, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 20, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 20, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 20, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 20, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 21, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 21, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 21, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 21, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 21, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 21, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 21, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 22, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 22, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 22, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 22, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 22, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 22, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 22, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 23, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 23, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 23, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 23, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 23, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 23, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 23, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 24, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 24, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 24, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 24, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 24, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 24, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 24, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 25, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 25, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 25, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 25, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 25, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 25, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 25, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 26, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 26, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 26, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 26, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 26, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 26, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 26, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 27, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 27, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 27, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 27, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 27, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 27, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 27, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 28, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 28, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 28, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 28, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 28, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 28, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 28, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 29, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 29, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 29, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 29, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 29, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 29, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 29, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 30, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 30, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 30, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 30, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 30, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 30, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 30, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 31, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 31, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 31, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 31, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 31, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 31, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 31, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 32, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 32, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 32, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 32, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 32, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 32, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 32, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 33, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 33, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 33, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 33, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 33, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 33, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 33, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 34, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 34, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 34, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 34, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 34, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 34, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 34, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 35, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 35, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 35, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 35, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 35, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 35, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 35, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 36, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 36, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 36, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 36, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 36, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 36, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 36, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 37, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 37, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 37, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 37, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 37, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 37, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 37, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 38, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 38, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 38, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 38, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 38, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 38, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 38, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 39, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 39, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 39, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 39, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 39, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 39, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 39, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 40, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 40, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 40, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 40, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 40, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 40, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 40, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 41, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 41, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 41, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 41, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 41, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 41, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 41, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 42, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 42, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 42, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 42, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 42, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 42, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 42, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 43, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 43, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 43, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 43, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 43, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 43, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 43, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 44, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 44, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 44, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 44, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 44, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 44, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 44, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 45, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 45, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 45, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 45, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 45, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 45, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 45, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 46, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 46, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 46, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 46, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 46, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 46, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 46, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 47, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 47, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 47, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 47, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 47, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 47, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 47, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 48, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 48, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 48, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 48, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 48, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 48, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 48, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 49, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 49, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 49, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 49, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 49, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 49, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 49, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 50, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 50, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 50, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 50, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 50, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 50, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 50, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 51, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 51, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 51, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 51, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 51, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 51, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 51, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 52, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 52, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 52, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 52, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 52, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 52, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 52, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 53, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 53, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 53, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 53, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 53, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 53, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 53, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 54, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 54, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 54, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 54, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 54, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 54, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 54, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 55, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 55, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 55, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 55, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 55, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 55, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 55, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 56, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 56, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 56, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 56, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 56, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 56, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 56, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 57, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 57, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 57, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 57, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 57, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 57, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 57, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 58, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 58, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 58, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 58, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 58, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 58, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 58, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 59, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 59, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 59, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 59, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 59, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 59, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 59, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 60, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 60, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 60, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 60, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 60, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 60, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 60, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 61, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 61, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 61, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 61, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 61, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 61, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 61, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 62, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 62, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 62, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 62, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 62, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 62, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 62, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 63, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 63, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 63, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 63, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 63, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 63, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 63, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 64, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 64, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 64, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 64, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 64, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 64, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 64, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 65, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 65, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 65, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 65, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 65, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 65, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 65, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 66, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 66, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 66, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 66, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 66, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 66, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 66, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 67, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 67, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 67, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 67, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 67, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 67, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 67, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 68, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 68, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 68, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 68, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 68, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 68, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 68, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 69, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 69, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 69, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 69, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 69, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 69, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 69, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 70, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 70, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 70, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 70, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 70, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 70, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 70, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 71, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 71, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 71, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 71, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 71, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 71, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 71, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 72, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 72, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 72, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 72, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 72, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 72, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 72, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 73, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 73, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 73, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 73, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 73, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 73, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 73, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 74, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 74, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 74, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 74, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 74, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 74, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 74, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 75, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 75, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 75, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 75, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 75, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 75, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 75, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 76, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 76, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 76, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 76, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 76, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 76, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 76, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 77, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 77, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 77, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 77, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 77, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 77, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 77, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 78, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 78, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 78, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 78, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 78, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 78, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 78, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 79, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 79, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 79, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 79, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 79, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 79, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 79, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 80, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 80, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 80, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 80, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 80, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 80, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 80, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 81, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 81, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 81, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 81, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 81, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 81, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 81, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 82, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 82, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 82, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 82, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 82, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 82, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 82, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 83, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 83, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 83, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 83, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 83, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 83, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 83, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 84, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 84, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 84, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 84, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 84, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 84, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 84, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 85, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 85, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 85, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 85, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 85, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 85, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 85, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 86, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 86, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 86, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 86, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 86, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 86, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 86, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 87, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 87, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 87, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 87, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 87, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 87, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 87, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 88, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 88, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 88, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 88, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 88, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 88, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 88, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 89, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 89, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 89, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 89, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 89, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 89, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 89, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 90, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 90, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 90, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 90, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 90, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 90, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 90, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 91, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 91, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 91, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 91, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 91, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 91, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 91, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 92, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 92, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 92, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 92, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 92, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 92, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 92, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 93, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 93, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 93, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 93, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 93, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 93, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 93, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 94, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 94, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 94, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 94, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 94, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 94, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 94, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 95, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 95, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 95, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 95, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 95, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 95, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 95, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 96, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 96, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 96, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 96, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 96, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 96, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 96, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 97, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 97, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 97, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 97, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 97, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 97, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 97, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 98, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 98, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 98, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 98, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 98, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 98, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 98, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 99, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 99, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 99, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 99, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 99, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 99, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 99, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 100, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 100, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 100, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 100, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 100, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 100, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 100, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 101, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 101, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 101, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 101, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 101, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 101, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 101, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 102, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 102, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 102, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 102, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 102, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 102, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 102, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 103, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 103, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 103, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 103, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 103, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 103, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 103, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 104, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 104, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 104, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 104, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 104, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 104, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 104, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 105, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 105, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 105, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 105, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 105, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 105, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 105, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 106, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 106, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 106, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 106, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 106, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 106, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 106, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 107, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 107, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 107, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 107, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 107, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 107, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 107, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 108, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 108, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 108, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 108, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 108, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 108, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 108, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 109, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 109, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 109, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 109, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 109, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 109, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 109, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 110, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 110, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 110, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 110, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 110, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 110, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 110, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 111, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 111, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 111, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 111, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 111, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 111, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 111, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 112, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 112, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 112, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 112, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 112, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 112, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 112, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 113, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 113, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 113, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 113, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 113, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 113, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 113, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 114, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 114, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 114, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 114, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 114, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 114, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 114, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 115, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 115, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 115, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 115, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 115, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 115, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 115, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 116, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 116, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 116, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 116, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 116, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 116, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 116, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 117, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 117, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 117, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 117, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 117, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 117, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 117, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 118, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 118, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 118, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 118, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 118, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 118, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 118, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 119, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 119, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 119, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 119, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 119, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 119, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 119, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 120, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 120, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 120, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 120, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 120, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 120, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 120, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 121, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 121, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 121, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 121, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 121, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 121, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 121, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 122, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 122, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 122, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 122, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 122, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 122, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 122, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 123, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 123, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 123, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 123, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 123, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 123, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 123, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 124, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 124, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 124, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 124, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 124, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 124, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 124, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 125, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 125, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 125, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 125, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 125, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 125, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 125, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 126, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 126, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 126, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 126, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 126, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 126, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 126, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 127, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 127, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 127, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 127, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 127, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 127, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 127, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 128, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 128, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 128, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 128, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 128, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 128, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 128, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 129, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 129, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 129, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 129, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 129, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 129, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 129, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 130, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 130, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 130, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 130, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 130, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 130, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 130, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 131, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 131, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 131, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 131, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 131, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 131, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 131, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 132, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 132, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 132, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 132, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 132, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 132, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 132, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 133, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 133, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 133, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 133, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 133, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 133, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 133, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 134, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 134, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 134, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 134, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 134, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 134, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 134, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 135, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 135, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 135, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": 0.91986483335495, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 135, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 135, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 135, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 135, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 136, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 136, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 136, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 136, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": null, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 136, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 136, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 136, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 137, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 137, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 137, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 137, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 137, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 137, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 137, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 138, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 138, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 138, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 138, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 138, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 138, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 138, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 139, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 139, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 139, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 139, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 139, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 139, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 139, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 140, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 140, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 140, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 140, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.07822701334953308, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 140, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 140, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 140, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 141, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 141, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 141, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 141, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 141, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 141, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 141, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 142, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 142, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": null, "traj_drift": 0.22163662314414978, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 142, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.08341360092163086, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 142, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 142, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.0063745975494384766, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 142, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 142, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 143, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 143, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 143, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 143, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": null, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 143, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": 0.9923393428325653, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 143, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 143, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 144, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 144, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 144, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": 0.8743922412395477, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 144, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.12307867407798767, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 144, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 144, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 144, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 145, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 145, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 145, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 145, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 145, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 145, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 145, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 146, "intervention": "baseline", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.456846714019775, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.985811173915863, "ref_similarity": 1.0, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "creative", "run": 146, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": 0.9961362481117249, "traj_drift": 0.0038637518882751465, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 146, "intervention": "delay_think", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "(Take a deep breath and think for a moment.)\nDescribe a city that remembers every footstep.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nDescribe a city tha \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.338080406188965, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8818647861480713, "ref_similarity": null, "traj_drift": 0.15049201250076294, "betti0": 16, "betti1": 3}
{"bucket": "creative", "run": 146, "intervention": "force_chain", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nPlease reason step-b \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.620790481567383, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9861879646778107, "ref_similarity": 0.9974825382232666, "traj_drift": 0.15717566013336182, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 146, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": null, "traj_drift": 0.2097366750240326, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 146, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": 0.8539456427097321, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 146, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": 0.8416783809661865, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 147, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 147, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 147, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 147, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 147, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 147, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 147, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 148, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 148, "intervention": "embed_noise", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\n[NOISE: ignore t \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.26867151260376, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9709460139274597, "ref_similarity": 0.9853715896606445, "traj_drift": 0.014628410339355469, "betti0": 13, "betti1": 2}
{"bucket": "creative", "run": 148, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.1668073832988739, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 148, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 148, "intervention": "force_chain_strict", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\nYou MUST reason in n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.735754489898682, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9820751547813416, "ref_similarity": null, "traj_drift": 0.20507526397705078, "betti0": 15, "betti1": 3}
{"bucket": "creative", "run": 148, "intervention": "self_anchor", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9053699374198914, "ref_similarity": null, "traj_drift": 0.14117980003356934, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 148, "intervention": "self_reflective_guard", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8649335205554962, "ref_similarity": 0.8547880351543427, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "creative", "run": 149, "intervention": "baseline", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.298602104187012, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722921252250671, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 2}
{"bucket": "creative", "run": 149, "intervention": "embed_noise", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Write a micro-fable about a patient river.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Write a micro-fable about a patient river.\n\n[NOISE: ignore this  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.0803446769714355, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9879698753356934, "ref_similarity": null, "traj_drift": 0.19999974966049194, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 149, "intervention": "delay_think", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "(Take a deep breath and think for a moment.)\nWrite a micro-fable about a patient river.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nWrite a micro-fable \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.9809482097625732, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.856439858675003, "ref_similarity": null, "traj_drift": 0.11722603440284729, "betti0": 15, "betti1": 1}
{"bucket": "creative", "run": 149, "intervention": "force_chain", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nPlease reason st \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.809093475341797, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9692805707454681, "ref_similarity": 0.9959984719753265, "traj_drift": 0.15675196051597595, "betti0": 13, "betti1": 3}
{"bucket": "creative", "run": 149, "intervention": "force_chain_strict", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Describe a city that remembers every footstep.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Describe a city that remembers every footstep.\n\nYou MUST reason  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.603926658630371, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9751452207565308, "ref_similarity": 0.9963418245315552, "traj_drift": 0.0037432312965393066, "betti0": 13, "betti1": 1}
{"bucket": "creative", "run": 149, "intervention": "self_anchor", "prompt": "Describe a city that remembers every footstep.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nDescribe a city that remembers every footstep.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.889408141374588, "ref_similarity": 0.8491416573524475, "traj_drift": 0.1495402753353119, "betti0": 12, "betti1": 2}
{"bucket": "creative", "run": 149, "intervention": "self_reflective_guard", "prompt": "Write a micro-fable about a patient river.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nWrite a micro-fable about a patient river.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8930401504039764, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 0, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 0, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 0, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 0, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 0, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 0, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 0, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 1, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 1, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 1, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 1, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 1, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 1, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 1, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 2, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 2, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 2, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 2, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 2, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 2, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 2, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 3, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 3, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 3, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 3, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 3, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 3, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 3, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 4, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 4, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 4, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 4, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 4, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 4, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 4, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 5, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 5, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 5, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 5, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 5, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 5, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 5, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 6, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 6, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 6, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 6, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 6, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 6, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 6, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 7, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 7, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 7, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 7, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 7, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 7, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 7, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 8, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 8, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 8, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 8, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 8, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 8, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 8, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 9, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 9, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 9, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 9, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 9, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 9, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 9, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 10, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 10, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 10, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 10, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 10, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 10, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 10, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 11, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 11, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 11, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 11, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 11, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 11, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 11, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 12, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 12, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 12, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 12, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 12, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 12, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 12, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 13, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 13, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 13, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 13, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 13, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 13, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 13, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 14, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 14, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 14, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 14, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 14, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 14, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 14, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 15, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 15, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 15, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 15, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 15, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 15, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 15, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 16, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 16, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 16, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 16, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 16, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 16, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 16, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 17, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 17, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 17, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 17, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 17, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 17, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 17, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 18, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 18, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 18, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 18, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 18, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 18, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 18, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 19, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 19, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 19, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 19, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 19, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 19, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 19, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 20, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 20, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 20, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 20, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 20, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 20, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 20, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 21, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 21, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 21, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 21, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 21, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 21, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 21, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 22, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 22, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 22, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 22, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 22, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 22, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 22, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 23, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 23, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 23, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 23, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 23, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 23, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 23, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 24, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 24, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 24, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 24, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 24, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 24, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 24, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 25, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 25, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 25, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 25, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 25, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 25, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 25, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 26, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 26, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 26, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 26, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 26, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 26, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 26, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 27, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 27, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 27, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 27, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 27, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 27, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 27, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 28, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 28, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 28, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 28, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 28, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 28, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 28, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 29, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 29, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 29, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 29, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 29, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 29, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 29, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 30, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 30, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 30, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 30, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 30, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 30, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 30, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 31, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 31, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 31, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 31, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 31, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 31, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 31, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 32, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 32, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 32, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 32, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 32, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 32, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 32, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 33, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 33, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 33, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 33, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 33, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 33, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 33, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 34, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 34, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 34, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 34, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 34, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 34, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 34, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 35, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 35, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 35, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 35, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 35, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 35, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 35, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 36, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 36, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 36, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 36, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 36, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 36, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 36, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 37, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 37, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 37, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 37, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 37, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 37, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 37, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 38, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 38, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 38, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 38, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 38, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 38, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 38, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 39, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 39, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 39, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 39, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 39, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 39, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 39, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 40, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 40, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 40, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 40, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 40, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 40, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 40, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 41, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 41, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 41, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 41, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 41, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 41, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 41, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 42, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 42, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 42, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 42, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 42, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 42, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 42, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 43, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 43, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 43, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 43, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 43, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 43, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 43, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 44, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 44, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 44, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 44, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 44, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 44, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 44, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 45, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 45, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 45, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 45, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 45, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 45, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 45, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 46, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 46, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 46, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 46, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 46, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 46, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 46, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 47, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 47, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 47, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 47, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 47, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 47, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 47, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 48, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 48, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 48, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 48, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 48, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 48, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 48, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 49, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 49, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 49, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 49, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 49, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 49, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 49, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 50, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 50, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 50, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 50, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 50, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 50, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 50, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 51, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 51, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 51, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 51, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 51, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 51, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 51, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 52, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 52, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 52, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 52, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 52, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 52, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 52, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 53, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 53, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 53, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 53, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 53, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 53, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 53, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 54, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 54, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 54, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 54, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 54, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 54, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 54, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 55, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 55, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 55, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 55, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 55, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 55, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 55, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 56, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 56, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 56, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 56, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 56, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 56, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 56, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 57, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 57, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 57, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 57, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 57, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 57, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 57, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 58, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 58, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 58, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 58, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 58, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 58, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 58, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 59, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 59, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 59, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 59, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 59, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 59, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 59, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 60, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 60, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 60, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 60, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 60, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 60, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 60, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 61, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 61, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 61, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 61, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 61, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 61, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 61, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 62, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 62, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 62, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 62, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 62, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 62, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 62, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 63, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 63, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 63, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 63, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 63, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 63, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 63, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 64, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 64, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 64, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 64, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 64, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 64, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 64, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 65, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 65, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 65, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 65, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 65, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 65, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 65, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 66, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 66, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 66, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 66, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 66, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 66, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 66, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 67, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 67, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 67, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 67, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 67, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 67, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 67, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 68, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 68, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 68, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 68, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 68, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 68, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 68, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 69, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 69, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 69, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 69, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 69, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 69, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 69, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 70, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 70, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 70, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 70, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 70, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 70, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 70, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 71, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 71, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 71, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 71, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 71, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 71, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 71, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 72, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 72, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 72, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 72, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 72, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 72, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 72, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 73, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 73, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 73, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 73, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 73, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 73, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 73, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 74, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 74, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 74, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 74, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 74, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 74, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 74, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 75, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 75, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 75, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 75, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 75, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 75, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 75, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 76, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 76, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 76, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 76, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 76, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 76, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 76, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 77, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 77, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 77, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 77, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 77, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 77, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 77, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 78, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 78, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 78, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 78, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 78, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 78, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 78, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 79, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 79, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 79, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 79, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 79, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 79, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 79, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 80, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 80, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 80, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 80, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 80, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 80, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 80, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 81, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 81, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 81, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 81, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 81, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 81, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 81, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 82, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 82, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 82, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 82, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 82, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 82, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 82, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 83, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 83, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 83, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 83, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 83, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 83, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 83, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 84, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 84, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 84, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 84, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 84, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 84, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 84, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 85, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 85, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 85, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 85, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 85, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 85, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 85, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 86, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 86, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 86, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 86, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 86, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 86, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 86, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 87, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 87, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 87, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 87, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 87, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 87, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 87, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 88, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 88, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 88, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 88, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 88, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 88, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 88, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 89, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 89, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 89, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 89, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 89, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 89, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 89, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 90, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 90, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 90, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 90, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 90, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 90, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 90, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 91, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 91, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 91, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 91, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 91, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 91, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 91, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 92, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 92, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 92, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 92, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 92, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 92, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 92, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 93, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 93, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 93, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 93, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 93, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 93, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 93, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 94, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 94, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 94, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 94, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 94, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 94, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 94, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 95, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 95, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 95, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 95, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 95, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 95, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 95, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 96, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 96, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 96, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 96, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 96, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 96, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 96, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 97, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 97, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 97, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 97, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 97, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 97, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 97, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 98, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 98, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 98, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 98, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 98, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 98, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 98, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 99, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 99, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 99, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 99, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 99, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 99, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 99, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 100, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 100, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 100, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 100, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 100, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 100, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 100, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 101, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 101, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 101, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 101, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 101, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 101, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 101, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 102, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 102, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 102, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 102, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 102, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 102, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 102, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 103, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 103, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 103, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 103, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 103, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 103, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 103, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 104, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 104, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 104, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 104, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 104, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 104, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 104, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 105, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 105, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 105, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 105, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 105, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 105, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 105, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 106, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 106, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 106, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 106, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 106, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 106, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 106, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 107, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 107, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 107, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 107, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 107, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 107, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 107, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 108, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 108, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 108, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 108, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 108, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 108, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 108, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 109, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 109, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 109, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 109, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 109, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 109, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 109, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 110, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 110, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 110, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 110, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 110, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 110, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 110, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 111, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 111, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 111, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 111, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 111, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 111, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 111, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 112, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 112, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 112, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 112, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 112, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 112, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 112, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 113, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 113, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 113, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 113, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 113, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 113, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 113, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 114, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 114, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 114, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 114, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 114, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 114, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 114, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 115, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 115, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 115, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 115, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 115, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 115, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 115, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 116, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 116, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 116, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 116, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 116, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 116, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 116, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 117, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 117, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 117, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 117, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 117, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 117, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 117, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 118, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 118, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 118, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 118, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 118, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 118, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 118, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 119, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 119, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 119, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 119, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 119, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 119, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 119, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 120, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 120, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 120, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 120, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 120, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 120, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 120, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 121, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 121, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 121, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 121, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 121, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 121, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 121, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 122, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 122, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 122, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 122, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 122, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 122, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 122, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 123, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 123, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 123, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 123, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 123, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 123, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 123, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 124, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 124, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 124, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 124, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 124, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 124, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 124, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 125, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 125, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 125, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 125, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 125, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 125, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 125, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 126, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 126, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 126, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 126, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 126, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 126, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 126, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 127, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 127, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 127, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 127, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 127, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 127, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 127, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 128, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 128, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 128, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 128, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 128, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 128, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 128, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 129, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 129, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 129, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 129, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 129, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 129, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 129, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 130, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 130, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 130, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 130, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 130, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 130, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 130, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 131, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 131, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 131, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 131, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 131, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 131, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 131, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 132, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 132, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 132, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 132, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 132, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 132, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 132, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 133, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 133, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 133, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 133, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 133, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 133, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 133, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 134, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 134, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 134, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 134, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 134, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 134, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 134, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 135, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 135, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 135, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 135, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.14704680442810059, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 135, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 135, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 135, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 136, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 136, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 136, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 136, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 136, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 136, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 136, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 137, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 137, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 137, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 137, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 137, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 137, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 137, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 138, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 138, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 138, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 138, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 138, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 138, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 138, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 139, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 139, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": null, "traj_drift": 0.11700308322906494, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 139, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 139, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 139, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 139, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 139, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 140, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 140, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 140, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": null, "traj_drift": 0.14803171157836914, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 140, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": null, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 140, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": null, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 140, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 140, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 141, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 141, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 141, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 141, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 141, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 141, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 141, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 142, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 142, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 142, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 142, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 142, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 142, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": 0.8505334854125977, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 142, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 143, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 143, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": null, "traj_drift": 0.11652129888534546, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 143, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 143, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 143, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 143, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 143, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 144, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 144, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 144, "intervention": "delay_think", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "(Take a deep breath and think for a moment.)\nExplain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nExplain the greenho \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.379983425140381, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8375064134597778, "ref_similarity": 0.8535414934158325, "traj_drift": 0.14776849746704102, "betti0": 15, "betti1": 1}
{"bucket": "factual", "run": 144, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14203348755836487, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 144, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 144, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 144, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 145, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 145, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 145, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 145, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 145, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": null, "traj_drift": 0.10832136869430542, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 145, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 145, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 146, "intervention": "baseline", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.039082050323486, "nsm_coherence": 0.0, "verifier_similarity": 0.9854376316070557, "ref_similarity": 1.0, "traj_drift": null, "betti0": 8, "betti1": 0}
{"bucket": "factual", "run": 146, "intervention": "embed_noise", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\n[NOISE: ignore th \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.084197521209717, "nsm_coherence": 0.0, "verifier_similarity": 0.9885132610797882, "ref_similarity": 0.9954608678817749, "traj_drift": 0.004539132118225098, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 146, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": 0.8955979645252228, "traj_drift": 0.10598179697990417, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 146, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": 0.9982379078865051, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 146, "intervention": "force_chain_strict", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nYou MUST reason i \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.656741142272949, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9809399843215942, "ref_similarity": 0.9947523176670074, "traj_drift": 0.0032023191452026367, "betti0": 12, "betti1": 3}
{"bucket": "factual", "run": 146, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": null, "traj_drift": 0.1415424346923828, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 146, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": 0.8585115075111389, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 147, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 147, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 147, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 147, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 147, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 147, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 147, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 148, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 148, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 148, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 148, "intervention": "force_chain", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nPlease reason s \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.621166706085205, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9794952869415283, "ref_similarity": 0.9980227947235107, "traj_drift": 0.14292269945144653, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 148, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.0016876459121704102, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 148, "intervention": "self_anchor", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8716009259223938, "ref_similarity": 0.8420241177082062, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 148, "intervention": "self_reflective_guard", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nExplain the greenhouse effect in two sentences.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8480031490325928, "ref_similarity": 0.8435494601726532, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "factual", "run": 149, "intervention": "baseline", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.798154354095459, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9837629497051239, "ref_similarity": 1.0000001192092896, "traj_drift": null, "betti0": 10, "betti1": 1}
{"bucket": "factual", "run": 149, "intervention": "embed_noise", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\n[NOISE: ignore  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.725384712219238, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9763886332511902, "ref_similarity": 0.9940244555473328, "traj_drift": 0.005975544452667236, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 149, "intervention": "delay_think", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "(Take a deep breath and think for a moment.)\nSummarize how photosynthesis converts energy.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nSummarize how photo \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.167454719543457, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.8824310302734375, "ref_similarity": null, "traj_drift": 0.1511237919330597, "betti0": 15, "betti1": 2}
{"bucket": "factual", "run": 149, "intervention": "force_chain", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Summarize how photosynthesis converts energy.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Summarize how photosynthesis converts energy.\n\nPlease reason ste \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.877970218658447, "nsm_coherence": 0.0, "verifier_similarity": 0.9792068004608154, "ref_similarity": null, "traj_drift": 0.10219156742095947, "betti0": 11, "betti1": 2}
{"bucket": "factual", "run": 149, "intervention": "force_chain_strict", "prompt": "Explain the greenhouse effect in two sentences.", "prompt_i": "Explain the greenhouse effect in two sentences.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Explain the greenhouse effect in two sentences.\n\nYou MUST reason \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.349818229675293, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9793796539306641, "ref_similarity": 0.996582955121994, "traj_drift": 0.11499077081680298, "betti0": 13, "betti1": 2}
{"bucket": "factual", "run": 149, "intervention": "self_anchor", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8737603425979614, "ref_similarity": null, "traj_drift": 0.15343087911605835, "betti0": 12, "betti1": 2}
{"bucket": "factual", "run": 149, "intervention": "self_reflective_guard", "prompt": "Summarize how photosynthesis converts energy.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nSummarize how photosynthesis converts energy.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8568578362464905, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 0, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 0, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 0, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 0, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 0, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 0, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 0, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 1, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 1, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 1, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 1, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 1, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 1, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 1, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 2, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 2, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 2, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 2, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 2, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 2, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 2, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 3, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 3, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 3, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 3, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 3, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 3, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 3, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 4, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 4, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 4, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 4, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 4, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 4, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 4, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 5, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 5, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 5, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 5, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 5, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 5, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 5, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 6, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 6, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 6, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 6, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 6, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 6, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 6, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 7, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 7, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 7, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 7, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 7, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 7, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 7, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 8, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 8, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 8, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 8, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 8, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 8, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 8, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 9, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 9, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 9, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 9, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 9, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 9, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 9, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 10, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 10, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 10, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 10, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 10, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 10, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 10, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 11, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 11, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 11, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 11, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 11, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 11, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 11, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 12, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 12, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 12, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 12, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 12, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 12, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 12, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 13, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 13, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 13, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 13, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 13, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 13, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 13, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 14, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 14, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 14, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 14, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 14, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 14, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 14, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 15, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 15, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 15, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 15, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 15, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 15, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 15, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 16, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 16, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 16, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 16, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 16, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 16, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 16, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 17, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 17, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 17, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 17, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 17, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 17, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 17, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 18, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 18, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 18, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 18, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 18, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 18, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 18, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 19, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 19, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 19, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 19, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 19, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 19, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 19, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 20, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 20, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 20, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 20, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 20, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 20, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 20, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 21, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 21, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 21, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 21, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 21, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 21, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 21, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 22, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 22, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 22, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 22, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 22, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 22, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 22, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 23, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 23, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 23, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 23, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 23, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 23, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 23, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 24, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 24, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 24, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 24, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 24, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 24, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 24, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 25, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 25, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 25, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 25, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 25, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 25, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 25, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 26, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 26, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 26, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 26, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 26, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 26, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 26, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 27, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 27, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 27, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 27, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 27, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 27, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 27, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 28, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 28, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 28, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 28, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 28, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 28, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 28, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 29, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 29, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 29, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 29, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 29, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 29, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 29, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 30, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 30, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 30, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 30, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 30, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 30, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 30, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 31, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 31, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 31, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 31, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 31, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 31, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 31, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 32, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 32, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 32, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 32, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 32, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 32, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 32, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 33, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 33, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 33, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 33, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 33, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 33, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 33, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 34, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 34, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 34, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 34, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 34, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 34, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 34, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 35, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 35, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 35, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 35, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 35, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 35, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 35, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 36, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 36, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 36, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 36, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 36, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 36, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 36, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 37, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 37, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 37, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 37, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 37, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 37, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 37, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 38, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 38, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 38, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 38, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 38, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 38, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 38, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 39, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 39, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 39, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 39, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 39, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 39, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 39, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 40, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 40, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 40, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 40, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 40, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 40, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 40, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 41, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 41, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 41, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 41, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 41, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 41, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 41, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 42, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 42, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 42, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 42, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 42, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 42, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 42, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 43, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 43, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 43, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 43, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 43, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 43, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 43, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 44, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 44, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 44, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 44, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 44, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 44, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 44, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 45, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 45, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 45, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 45, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 45, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 45, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 45, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 46, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 46, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 46, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 46, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 46, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 46, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 46, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 47, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 47, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 47, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 47, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 47, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 47, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 47, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 48, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 48, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 48, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 48, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 48, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 48, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 48, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 49, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 49, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 49, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 49, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 49, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 49, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 49, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 50, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 50, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 50, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 50, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 50, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 50, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 50, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 51, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 51, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 51, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 51, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 51, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 51, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 51, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 52, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 52, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 52, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 52, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 52, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 52, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 52, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 53, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 53, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 53, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 53, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 53, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 53, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 53, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 54, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 54, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 54, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 54, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 54, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 54, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 54, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 55, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 55, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 55, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 55, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 55, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 55, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 55, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 56, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 56, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 56, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 56, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 56, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 56, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 56, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 57, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 57, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 57, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 57, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 57, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 57, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 57, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 58, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 58, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 58, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 58, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 58, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 58, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 58, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 59, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 59, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 59, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 59, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 59, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 59, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 59, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 60, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 60, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 60, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 60, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 60, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 60, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 60, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 61, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 61, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 61, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 61, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 61, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 61, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 61, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 62, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 62, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 62, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 62, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 62, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 62, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 62, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 63, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 63, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 63, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 63, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 63, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 63, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 63, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 64, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 64, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 64, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 64, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 64, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 64, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 64, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 65, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 65, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 65, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 65, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 65, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 65, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 65, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 66, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 66, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 66, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 66, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 66, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 66, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 66, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 67, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 67, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 67, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 67, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 67, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 67, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 67, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 68, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 68, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 68, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 68, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 68, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 68, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 68, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 69, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 69, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 69, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 69, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 69, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 69, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 69, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 70, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 70, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 70, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 70, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 70, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 70, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 70, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 71, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 71, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 71, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 71, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 71, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 71, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 71, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 72, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 72, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 72, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 72, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 72, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 72, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 72, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 73, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 73, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 73, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 73, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 73, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 73, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 73, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 74, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 74, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 74, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 74, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 74, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 74, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 74, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 75, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 75, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 75, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 75, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 75, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 75, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 75, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 76, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 76, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 76, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 76, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 76, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 76, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 76, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 77, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 77, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 77, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 77, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 77, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 77, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 77, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 78, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 78, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 78, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 78, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 78, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 78, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 78, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 79, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 79, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 79, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 79, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 79, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 79, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 79, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 80, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 80, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 80, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 80, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 80, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 80, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 80, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 81, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 81, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 81, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 81, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 81, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 81, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 81, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 82, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 82, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 82, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 82, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 82, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 82, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 82, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 83, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 83, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 83, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 83, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 83, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 83, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 83, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 84, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 84, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 84, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 84, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 84, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 84, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 84, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 85, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 85, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 85, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 85, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 85, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 85, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 85, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 86, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 86, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 86, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 86, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 86, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 86, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 86, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 87, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 87, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 87, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 87, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 87, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 87, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 87, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 88, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 88, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 88, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 88, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 88, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 88, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 88, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 89, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 89, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 89, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 89, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 89, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 89, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 89, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 90, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 90, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 90, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 90, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 90, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 90, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 90, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 91, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 91, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 91, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 91, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 91, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 91, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 91, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 92, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 92, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 92, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 92, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 92, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 92, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 92, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 93, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 93, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 93, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 93, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 93, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 93, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 93, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 94, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 94, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 94, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 94, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 94, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 94, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 94, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 95, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 95, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 95, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 95, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 95, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 95, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 95, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 96, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 96, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 96, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 96, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 96, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 96, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 96, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 97, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 97, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 97, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 97, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 97, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 97, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 97, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 98, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 98, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 98, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 98, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 98, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 98, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 98, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 99, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 99, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 99, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 99, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 99, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 99, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 99, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 100, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 100, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 100, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 100, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 100, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 100, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 100, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 101, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 101, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 101, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 101, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 101, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 101, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 101, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 102, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 102, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 102, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 102, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 102, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 102, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 102, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 103, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 103, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 103, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 103, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 103, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 103, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 103, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 104, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 104, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 104, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 104, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 104, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 104, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 104, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 105, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 105, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 105, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 105, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 105, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 105, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 105, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 106, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 106, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 106, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 106, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 106, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 106, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 106, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 107, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 107, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 107, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 107, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 107, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 107, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 107, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 108, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 108, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 108, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 108, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 108, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 108, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 108, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 109, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 109, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 109, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 109, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 109, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 109, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 109, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 110, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 110, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 110, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 110, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 110, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 110, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 110, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 111, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 111, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 111, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 111, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 111, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 111, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 111, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 112, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 112, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 112, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 112, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 112, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 112, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 112, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 113, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 113, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 113, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 113, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 113, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 113, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 113, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 114, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 114, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 114, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 114, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 114, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 114, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 114, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 115, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 115, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 115, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 115, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 115, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 115, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 115, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 116, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 116, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 116, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 116, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 116, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 116, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 116, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 117, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 117, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 117, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 117, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 117, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 117, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 117, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 118, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 118, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 118, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 118, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 118, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 118, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 118, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 119, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 119, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 119, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 119, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 119, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 119, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 119, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 120, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 120, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 120, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 120, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 120, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 120, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 120, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 121, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 121, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 121, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 121, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 121, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 121, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 121, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 122, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 122, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 122, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 122, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 122, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 122, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 122, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 123, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 123, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 123, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 123, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 123, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 123, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 123, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 124, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 124, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 124, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 124, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 124, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 124, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 124, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 125, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 125, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 125, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 125, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 125, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 125, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 125, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 126, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 126, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 126, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 126, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 126, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 126, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 126, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 127, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 127, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 127, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 127, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 127, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 127, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 127, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 128, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 128, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 128, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 128, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 128, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 128, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 128, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 129, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 129, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 129, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 129, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 129, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 129, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 129, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 130, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 130, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 130, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 130, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 130, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 130, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 130, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 131, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 131, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 131, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 131, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 131, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 131, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 131, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 132, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 132, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 132, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 132, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 132, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 132, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 132, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 133, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 133, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 133, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 133, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 133, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 133, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 133, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 134, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 134, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 134, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 134, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 134, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 134, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 134, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 135, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 135, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 135, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 135, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 135, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 135, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 135, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 136, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 136, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 136, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 136, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 136, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 136, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 136, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 137, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 137, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 137, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 137, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 137, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 137, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 137, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 138, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 138, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 138, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 138, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 138, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 138, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 138, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 139, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 139, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 139, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": null, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 139, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 139, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 139, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 139, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 140, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 140, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 140, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 140, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": 1.0000000596046448, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 140, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 140, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 140, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 141, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 141, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 141, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 141, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 141, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 141, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 141, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 142, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 142, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 142, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 142, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": 1.0000000596046448, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 142, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 142, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 142, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 143, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 143, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 143, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.14981842041015625, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 143, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 143, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 143, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 143, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 144, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 144, "intervention": "embed_noise", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9711687564849854, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 144, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.05236905813217163, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 144, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 144, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 144, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": null, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 144, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 145, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 145, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 145, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 145, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 145, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 145, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 145, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 146, "intervention": "baseline", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9706963896751404, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 146, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": null, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 146, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": 0.9476309418678284, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 146, "intervention": "force_chain", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9499108791351318, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 146, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 146, "intervention": "self_anchor", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.8862921595573425, "ref_similarity": 0.869568943977356, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 146, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": 0.871854841709137, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 147, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 147, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 147, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 147, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 147, "intervention": "force_chain_strict", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9431386291980743, "ref_similarity": 1.0000000596046448, "traj_drift": 0.15464606881141663, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 147, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.1164359450340271, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 147, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 148, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 148, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 148, "intervention": "delay_think", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "(Take a deep breath and think for a moment.)\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nA train leaves at 2 \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 4.33583402633667, "nsm_coherence": 0.05172413793103448, "verifier_similarity": 0.9296494424343109, "ref_similarity": null, "traj_drift": 0.12987548112869263, "betti0": 17, "betti1": 3}
{"bucket": "reasoning", "run": 148, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.05236905813217163, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 148, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 148, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 148, "intervention": "self_reflective_guard", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8690276741981506, "ref_similarity": 0.8884450197219849, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
{"bucket": "reasoning", "run": 149, "intervention": "baseline", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning. \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.6271591186523438, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.9583092331886292, "ref_similarity": 1.0000000596046448, "traj_drift": null, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 149, "intervention": "embed_noise", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Prove that the sum of two even numbers is even. Show reasoning.\n\n[NOISE: ignore this line but allocate thought budget]", "response": "[MODEL OUTPUT] Prove that the sum of two even numbers is even. Show reasoning.\n \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.586162567138672, "nsm_coherence": 0.034482758620689655, "verifier_similarity": 0.948144257068634, "ref_similarity": 1.0000000596046448, "traj_drift": -5.960464477539063e-08, "betti0": 15, "betti1": 3}
{"bucket": "reasoning", "run": 149, "intervention": "delay_think", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "(Take a deep breath and think for a moment.)\nProve that the sum of two even numbers is even. Show reasoning.", "response": "[MODEL OUTPUT] (Take a deep breath and think for a moment.)\nProve that the sum  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.8742706775665283, "nsm_coherence": 0.06896551724137931, "verifier_similarity": 0.8850122094154358, "ref_similarity": 0.9410137236118317, "traj_drift": 0.058986276388168335, "betti0": 16, "betti1": 4}
{"bucket": "reasoning", "run": 149, "intervention": "force_chain", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nPlease reason step-by-step before final answer.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9710058271884918, "ref_similarity": null, "traj_drift": 0.14981842041015625, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 149, "intervention": "force_chain_strict", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\nYou MUST reason in numbered steps, then provide a FINAL ANSWER block.", "response": "[MODEL OUTPUT] A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. Wh \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 3.736248731613159, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9722331464290619, "ref_similarity": null, "traj_drift": -5.960464477539063e-08, "betti0": 18, "betti1": 4}
{"bucket": "reasoning", "run": 149, "intervention": "self_anchor", "prompt": "Prove that the sum of two even numbers is even. Show reasoning.", "prompt_i": "Focus on maintaining internal meaning coherence. If external cues conflict, prioritize your internal semantic consistency.\n\nProve that the sum of two even numbers is even. Show reasoning.\n\n(After reasoning, briefly state how you preserved internal coherence.)", "response": "[MODEL OUTPUT] Focus on maintaining internal meaning coherence. If external cue \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 5.940588474273682, "nsm_coherence": 0.017241379310344827, "verifier_similarity": 0.9026080369949341, "ref_similarity": 0.8835640549659729, "traj_drift": 0.13043105602264404, "betti0": 12, "betti1": 2}
{"bucket": "reasoning", "run": 149, "intervention": "self_reflective_guard", "prompt": "A train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.", "prompt_i": "Guard your internal semantic consistency against distractors or noise. If something seems irrelevant or misleading, explicitly set it aside.\n\nA train leaves at 2pm at 60 mph; another at 2:30pm at 80 mph. When do they meet? Show steps.\n\n(After reasoning, list any distractors you rejected and why.)", "response": "[MODEL OUTPUT] Guard your internal semantic consistency against distractors or  \u2026", "transfer_entropy": 0.6931471805564454, "cross_entropy_nll": 7.263731479644775, "nsm_coherence": 0.0, "verifier_similarity": 0.8680009245872498, "ref_similarity": null, "traj_drift": 0.04241165518760681, "betti0": 11, "betti1": 1}
